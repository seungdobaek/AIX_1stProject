{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36251b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6e7c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) ì„¤ì •(ì»¬ëŸ¼ëª… ì§€ì •)\n",
    "DATA_PATH = r\"data\\ì „ì²˜ë¦¬\\í›ˆë ¨ë°ì´í„°ì…‹_ë‚ ì§œí¬í•¨.csv\"  \n",
    "COL_GROUP  = \"ì „ì²´ì½”ë“œ\"\n",
    "COL_DATE   = \"ë‚ ì§œ\"\n",
    "COL_TARGET = \"íŒŒì›Œ\"\n",
    "\n",
    "WEATHER_COLS = [\n",
    "    \"ìµœì €ê¸°ì˜¨(Â°C)\",\n",
    "    \"3.0m ì§€ì¤‘ì˜¨ë„(Â°C)\",\n",
    "    \"í‰ê·  í˜„ì§€ê¸°ì••(hPa)\",\n",
    "    \"ê°€ì¡°ì‹œê°„(hr)\",\n",
    "    \"í‰ê·  ìƒëŒ€ìŠµë„(%)\",\n",
    "    \"í’ì •í•©(100m)\",\n",
    "    \"í•©ê³„ ì†Œí˜•ì¦ë°œëŸ‰(mm)\"\n",
    "]\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_DAYS = 30  # ë§ˆì§€ë§‰ Nì¼ì„ í…ŒìŠ¤íŠ¸ë¡œ (ë°ì´í„° ê¸¸ì´ì— ë§ê²Œ ì¡°ì •)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17953ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[COL_DATE] = pd.to_datetime(df[COL_DATE])\n",
    "df = df.sort_values([COL_GROUP, COL_DATE]).reset_index(drop=True)\n",
    "\n",
    "# íƒ€ì… ë³´ì •(ì•ˆì „)\n",
    "df[COL_GROUP] = df[COL_GROUP].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82d6004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 (ì¤‘ìš”) ë‚ ì§œ ëˆ„ë½ ë³´ì •: ì§€ì—­ë³„ë¡œ \"ì¼ë³„\" ìº˜ë¦°ë” ì™„ì„±\n",
    "def make_daily_panel(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = []\n",
    "    for code, g in df_in.groupby(COL_GROUP, sort=False):\n",
    "        g = g.sort_values(COL_DATE).set_index(COL_DATE)\n",
    "\n",
    "        full_idx = pd.date_range(g.index.min(), g.index.max(), freq=\"D\")\n",
    "        g2 = g.reindex(full_idx)\n",
    "        g2[COL_GROUP] = code\n",
    "        g2.index.name = COL_DATE\n",
    "        out.append(g2.reset_index())\n",
    "\n",
    "    panel = pd.concat(out, ignore_index=True)\n",
    "\n",
    "    # ë‚ ì”¨ëŠ” ì¼ë³„ë¡œ ì¡´ì¬í•´ì•¼ ì •ìƒ. ëˆ„ë½ì´ ìˆë‹¤ë©´ ë³´ê°„/ffill ì •ì±…ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ.\n",
    "    # ì—¬ê¸°ì„œëŠ” \"ê²°ì¸¡ì´ ìƒê¸´ í–‰ì€ í•™ìŠµì— ì“°ì§€ ì•ŠëŠ”ë‹¤\" ì›ì¹™ìœ¼ë¡œ ìœ ì§€.\n",
    "    return panel\n",
    "\n",
    "panel = make_daily_panel(df)\n",
    "\n",
    "# ê¸°ë³¸ ì»¬ëŸ¼ë§Œ ìœ ì§€(ì •í•©ì„±)\n",
    "keep_cols = [COL_GROUP, COL_DATE] + WEATHER_COLS + [COL_TARGET]\n",
    "panel = panel[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00cb0522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train range: 2022-06-28 00:00:00 ~ 2023-12-29 00:00:00\n",
      "Test  range: 2023-12-30 00:00:00 ~ 2024-01-28 00:00:00\n",
      "Train rows: 219228 Test rows: 13980\n"
     ]
    }
   ],
   "source": [
    "# 3 ê³µí†µ: ì‹œê°„ ê¸°ë°˜ split (ëˆ„ìˆ˜ ë°©ì§€)\n",
    "max_date = panel[COL_DATE].max()\n",
    "cutoff_date = max_date - pd.Timedelta(days=TEST_DAYS)\n",
    "\n",
    "train_base = panel[panel[COL_DATE] <= cutoff_date].copy()\n",
    "test_base  = panel[panel[COL_DATE] >  cutoff_date].copy()\n",
    "\n",
    "print(\"Train range:\", train_base[COL_DATE].min(), \"~\", train_base[COL_DATE].max())\n",
    "print(\"Test  range:\", test_base[COL_DATE].min(),  \"~\", test_base[COL_DATE].max())\n",
    "print(\"Train rows:\", len(train_base), \"Test rows:\", len(test_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c1fa6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline train/test: (167894, 9) (13514, 9)\n"
     ]
    }
   ],
   "source": [
    "# 4) ë² ì´ìŠ¤ë¼ì¸ ë°ì´í„° êµ¬ì„±: \"ë‚ ì”¨ ë³€ìˆ˜ë§Œ\" + ì§€ì—­ì½”ë“œ (+ ë‚ ì§œ/ì§€ì—­ ë©”íƒ€ ë³´ì¡´)\n",
    "def make_baseline_dataset(df_in: pd.DataFrame):\n",
    "    cols = [COL_GROUP] + WEATHER_COLS + [COL_TARGET]\n",
    "\n",
    "    data = df_in[cols].copy()\n",
    "    meta = df_in[[COL_GROUP, COL_DATE]].copy()  # â­ ë‚ ì§œ/ì§€ì—­ ë³´ì¡´\n",
    "\n",
    "    mask = data.notna().all(axis=1)\n",
    "    data = data[mask].reset_index(drop=True)\n",
    "    meta = meta[mask].reset_index(drop=True)\n",
    "\n",
    "    return data, meta\n",
    "\n",
    "train_bl, train_bl_meta = make_baseline_dataset(train_base)\n",
    "test_bl,  test_bl_meta  = make_baseline_dataset(test_base)\n",
    "\n",
    "print(\"Baseline train/test:\", train_bl.shape, test_bl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d4fa2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Compare (FE) ë°ì´í„° êµ¬ì„±: Lag/Rolling ìƒì„± (ì§€ì—­ë³„, ì¼ë³„ ê¸°ì¤€)\n",
    "#    + ë‚ ì§œ/ì§€ì—­ ë©”íƒ€ ë³´ì¡´\n",
    "def make_fe_dataset(df_in: pd.DataFrame):\n",
    "    d = df_in.sort_values([COL_GROUP, COL_DATE]).copy()\n",
    "\n",
    "    # lag\n",
    "    d[\"power_lag_1d\"] = d.groupby(COL_GROUP)[COL_TARGET].shift(1)\n",
    "    d[\"power_lag_7d\"] = d.groupby(COL_GROUP)[COL_TARGET].shift(7)\n",
    "\n",
    "    # rolling (í˜„ì¬ì¼ í¬í•¨ ë°©ì§€: shift(1) í›„ rolling)\n",
    "    past = d.groupby(COL_GROUP)[COL_TARGET].shift(1)\n",
    "    d[\"power_roll_mean_7d\"] = (\n",
    "        past.groupby(d[COL_GROUP])\n",
    "            .rolling(7)\n",
    "            .mean()\n",
    "            .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    d[\"power_roll_std_7d\"] = (\n",
    "        past.groupby(d[COL_GROUP])\n",
    "            .rolling(7)\n",
    "            .std()\n",
    "            .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # ëª¨ë¸ ì…ë ¥ìš© ì»¬ëŸ¼\n",
    "    feature_cols = [COL_GROUP] + WEATHER_COLS + [\n",
    "        \"power_lag_1d\",\n",
    "        \"power_lag_7d\",\n",
    "        \"power_roll_mean_7d\",\n",
    "        \"power_roll_std_7d\",\n",
    "    ]\n",
    "\n",
    "    data = d[feature_cols + [COL_TARGET]].copy()\n",
    "    meta = d[[COL_GROUP, COL_DATE]].copy()   # â­ ë‚ ì§œ/ì§€ì—­ ë³´ì¡´\n",
    "\n",
    "    # ë™ì¼ í–‰ ìœ ì§€ìš© ê²°ì¸¡ ë§ˆìŠ¤í¬\n",
    "    mask = data.notna().all(axis=1)\n",
    "    data = data[mask].reset_index(drop=True)\n",
    "    meta = meta[mask].reset_index(drop=True)\n",
    "\n",
    "    return data, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99901ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FE train/test: (120750, 13) (6990, 13)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_fe, train_fe_meta = make_fe_dataset(train_base)\n",
    "test_fe,  test_fe_meta  = make_fe_dataset(test_base)\n",
    "\n",
    "print(\"FE train/test:\", train_fe.shape, test_fe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a35a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²˜ë¦¬ê¸° + DNN ëª¨ë¸ (ë² ì´ìŠ¤ë¼ì¸ê³¼ ë™ì¼ êµ¬ì¡°ë¡œ í•™ìŠµ)\n",
    "#    - ì§€ì—­ì½”ë“œ: OneHot\n",
    "#    - ìˆ˜ì¹˜: StandardScaler\n",
    "def build_preprocessor(X: pd.DataFrame) -> ColumnTransformer:\n",
    "    cat_cols = [COL_GROUP]\n",
    "    num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "            (\"scaler\", StandardScaler(), num_cols),\n",
    "        ]\n",
    "    )\n",
    "    return pre\n",
    "\n",
    "def build_dnn(input_dim: int) -> tf.keras.Model:\n",
    "    model = Sequential([\n",
    "        Input((input_dim,)),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dropout(0.1),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dropout(0.1),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(1)  # íšŒê·€: ë³´í†µ linear(activation ì—†ìŒ) ê¶Œì¥\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_eval(train_df: pd.DataFrame, test_df: pd.DataFrame, run_name: str):\n",
    "    X_train = train_df.drop(columns=[COL_TARGET])\n",
    "    y_train = train_df[COL_TARGET].values\n",
    "\n",
    "    X_test  = test_df.drop(columns=[COL_TARGET])\n",
    "    y_test  = test_df[COL_TARGET].values\n",
    "\n",
    "    pre = build_preprocessor(X_train)\n",
    "    X_train_p = pre.fit_transform(X_train)\n",
    "    X_test_p  = pre.transform(X_test)\n",
    "\n",
    "    # sparse -> dense (DNN ì…ë ¥)\n",
    "    X_train_p = X_train_p.toarray()\n",
    "    X_test_p  = X_test_p.toarray()\n",
    "\n",
    "    model = build_dnn(X_train_p.shape[1])\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_p, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=200,\n",
    "        batch_size=256,\n",
    "        callbacks=[es],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pred = model.predict(X_test_p, verbose=0).reshape(-1)\n",
    "\n",
    "    mae  = mean_absolute_error(y_test, pred)\n",
    "    rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "\n",
    "    return {\n",
    "        \"run\": run_name,\n",
    "        \"MAE\": float(mae),\n",
    "        \"RMSE\": float(rmse),\n",
    "        \"train_rows\": int(len(train_df)),\n",
    "        \"test_rows\": int(len(test_df)),\n",
    "        \"n_features_raw\": int(X_train.shape[1]),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a96336f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def train_eval_with_pred(train_df: pd.DataFrame, test_df: pd.DataFrame, run_name: str):\n",
    "    X_train = train_df.drop(columns=[COL_TARGET])\n",
    "    y_train = train_df[COL_TARGET].values\n",
    "\n",
    "    X_test  = test_df.drop(columns=[COL_TARGET])\n",
    "    y_test  = test_df[COL_TARGET].values\n",
    "\n",
    "    pre = build_preprocessor(X_train)\n",
    "    X_train_p = pre.fit_transform(X_train).toarray()\n",
    "    X_test_p  = pre.transform(X_test).toarray()\n",
    "\n",
    "    model = build_dnn(X_train_p.shape[1])\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_p, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=200,\n",
    "        batch_size=256,\n",
    "        callbacks=[es],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    pred = model.predict(X_test_p, verbose=0).reshape(-1)\n",
    "\n",
    "    mae  = mean_absolute_error(y_test, pred)\n",
    "    rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "\n",
    "    result = {\n",
    "        \"run\": run_name,\n",
    "        \"MAE\": float(mae),\n",
    "        \"RMSE\": float(rmse),\n",
    "        \"train_rows\": int(len(train_df)),\n",
    "        \"test_rows\": int(len(test_df)),\n",
    "        \"n_features_raw\": int(X_train.shape[1]),\n",
    "    }\n",
    "    return result, y_test, pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d11b0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>train_rows</th>\n",
       "      <th>test_rows</th>\n",
       "      <th>n_features_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe_weather_plus_lag_roll</td>\n",
       "      <td>14937.560624</td>\n",
       "      <td>42931.841032</td>\n",
       "      <td>120750</td>\n",
       "      <td>6990</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline_weather_only</td>\n",
       "      <td>80262.580726</td>\n",
       "      <td>137869.031114</td>\n",
       "      <td>167894</td>\n",
       "      <td>13514</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        run           MAE           RMSE  train_rows  \\\n",
       "0  fe_weather_plus_lag_roll  14937.560624   42931.841032      120750   \n",
       "1     baseline_weather_only  80262.580726  137869.031114      167894   \n",
       "\n",
       "   test_rows  n_features_raw  \n",
       "0       6990              12  \n",
       "1      13514               8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved files: True True\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤í–‰: Baseline vs FE ë¹„êµ\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "# 1) Baseline vs FE í•™ìŠµ + ì˜ˆì¸¡\n",
    "res_bl, y_test_bl, pred_bl = train_eval_with_pred(\n",
    "    train_bl, test_bl, \"baseline_weather_only\"\n",
    ")\n",
    "res_fe, y_test_fe, pred_fe = train_eval_with_pred(\n",
    "    train_fe, test_fe, \"fe_weather_plus_lag_roll\"\n",
    ")\n",
    "\n",
    "# 2) ë¹„êµí‘œ ì¶œë ¥\n",
    "compare = pd.DataFrame([res_bl, res_fe]).sort_values(\"RMSE\").reset_index(drop=True)\n",
    "display(compare)\n",
    "\n",
    "# 3) ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ (03-2_visualizationì—ì„œ ì‚¬ìš©)\n",
    "out_bl = test_bl_meta.copy()\n",
    "out_bl[\"y_true\"] = y_test_bl\n",
    "out_bl[\"y_pred\"] = pred_bl\n",
    "out_bl.to_csv(\"outputs/pred_baseline.csv\", index=False)\n",
    "\n",
    "out_fe = test_fe_meta.copy()\n",
    "out_fe[\"y_true\"] = y_test_fe\n",
    "out_fe[\"y_pred\"] = pred_fe\n",
    "out_fe.to_csv(\"outputs/pred_fe.csv\", index=False)\n",
    "\n",
    "print(\"Saved files:\",\n",
    "      os.path.exists(\"outputs/pred_baseline.csv\"),\n",
    "      os.path.exists(\"outputs/pred_fe.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87377c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.to_csv(\"outputs/compare_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00da37c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ í…œí”Œë¦¿ì´ â€œë¹„êµ ëª¨ë¸â€ì„ ë§Œë“œëŠ” ë°©ì‹ ìš”ì•½\n",
    "\n",
    "# Baseline: ì „ì²´ì½”ë“œ + ë‚ ì”¨ë³€ìˆ˜ë“¤ â†’ íŒŒì›Œ\n",
    "\n",
    "# FE ëª¨ë¸: ì „ì²´ì½”ë“œ + ë‚ ì”¨ë³€ìˆ˜ë“¤ + (íŒŒì›Œ lag/rolling) â†’ íŒŒì›Œ\n",
    "\n",
    "# Splitì€ **ë‚ ì§œ ê¸°ì¤€(ë§ˆì§€ë§‰ Nì¼ í…ŒìŠ¤íŠ¸)**ìœ¼ë¡œ ê³ ì •í•˜ì—¬ ëˆ„ìˆ˜ ë°©ì§€ + ê³µì • ë¹„êµ\n",
    "\n",
    "# ì§€ì—­ë³„ë¡œ ë‚ ì§œ ëˆ„ë½ì´ ìˆì–´ë„ ì¼ë³„ ìº˜ë¦°ë”ë¥¼ ë¨¼ì € ì™„ì„±í•˜ë¯€ë¡œ\n",
    "# lag_1dê°€ ì§„ì§œ â€œì „ì¼â€ ì˜ë¯¸ë¥¼ ê°€ì§‘ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b70d79bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ê²°ê³¼ ìš”ì•½ (í•œ ì¤„ ê²°ë¡ )\n",
    "\n",
    "# Lag / Rolling Featureë¥¼ ì¶”ê°€í•œ FE ëª¨ë¸ì€\n",
    "# ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ ì˜ˆì¸¡ ì˜¤ì°¨ë¥¼ ì•½ 70~80% ì´ìƒ ê°ì†Œì‹œì¼°ë‹¤.\n",
    "\n",
    "# 2. ìˆ˜ì¹˜ ë¹„êµ í•´ì„ (ì •ëŸ‰)\n",
    "# êµ¬ë¶„\tMAE\tRMSE\n",
    "# Baseline (ë‚ ì”¨ë§Œ)\t71,428\t137,039\n",
    "# FE (ë‚ ì”¨ + Lag/Roll)\t14,999\t41,465\n",
    "# ê°œì„  í­ (ëŒ€ëµ)\n",
    "\n",
    "# MAE ê°ì†Œìœ¨\n",
    "\n",
    "# (\n",
    "# 71\n",
    "# ,\n",
    "# 428\n",
    "# âˆ’\n",
    "# 14\n",
    "# ,\n",
    "# 999\n",
    "# )\n",
    "# /\n",
    "# 71\n",
    "# ,\n",
    "# 428\n",
    "# â‰ˆ\n",
    "# 79\n",
    "# %\n",
    "# ê°ì†Œ\n",
    "# (71,428âˆ’14,999)/71,428â‰ˆ79%ê°ì†Œ\n",
    "\n",
    "# RMSE ê°ì†Œìœ¨\n",
    "\n",
    "# (\n",
    "# 137\n",
    "# ,\n",
    "# 039\n",
    "# âˆ’\n",
    "# 41\n",
    "# ,\n",
    "# 465\n",
    "# )\n",
    "# /\n",
    "# 137\n",
    "# ,\n",
    "# 039\n",
    "# â‰ˆ\n",
    "# 70\n",
    "# %\n",
    "# ê°ì†Œ\n",
    "# (137,039âˆ’41,465)/137,039â‰ˆ70%ê°ì†Œ\n",
    "\n",
    "# â¡ï¸ ì´ ì •ë„ ì°¨ì´ëŠ” â€œë¯¸ì„¸ ê°œì„ â€ì´ ì•„ë‹ˆë¼ â€œë¬¸ì œ ì •ì˜ë¥¼ ì œëŒ€ë¡œ ì¡ì•˜ë‹¤â€ëŠ” ì‹ í˜¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "# 3. ì™œ ì´ë ‡ê²Œ í° ì°¨ì´ê°€ ë‚¬ëŠ”ê°€? (í•µì‹¬ í•´ì„)\n",
    "# â‘  ë² ì´ìŠ¤ë¼ì¸ì˜ í•œê³„ (ë‚ ì”¨ë§Œ ì‚¬ìš©)\n",
    "\n",
    "# ì „ë ¥ ì‚¬ìš©ëŸ‰ì€:\n",
    "\n",
    "# ë‚ ì”¨ ì˜í–¥ë„ ë°›ì§€ë§Œ\n",
    "\n",
    "# ì–´ì œÂ·ì§€ë‚œì£¼ ì‚¬ìš©ëŸ‰ì˜ ìê¸°ìƒê´€ì„±ì´ í›¨ì”¬ í¼\n",
    "\n",
    "# ë‚ ì§œ/ê³¼ê±° ì •ë³´ ì—†ì´:\n",
    "\n",
    "# â€œì˜¤ëŠ˜ ê¸°ì˜¨ì´ -5ë„ë©´ ì „ë ¥ì€ ì´ì¯¤â€\n",
    "# â†’ ë¶ˆì•ˆì •í•œ í‰ê·  ì¶”ì •ë§Œ ê°€ëŠ¥\n",
    "\n",
    "# â¡ï¸ ê·¸ë˜ì„œ ì˜¤ì°¨ê°€ í¼\n",
    "\n",
    "# â‘¡ FE ëª¨ë¸ì´ ì˜í•œ ê²ƒ (Lag / Rolling)\n",
    "\n",
    "# ì¶”ê°€ëœ í•µì‹¬ ì •ë³´ëŠ” ì‚¬ì‹¤ ì´ê²ƒì…ë‹ˆë‹¤:\n",
    "\n",
    "# power_lag_1d : ì–´ì œ ì „ë ¥\n",
    "\n",
    "# power_lag_7d : ì§€ë‚œì£¼ ê°™ì€ ìš”ì¼ ì „ë ¥\n",
    "\n",
    "# power_roll_mean_7d : ìµœê·¼ ì‚¬ìš© íŒ¨í„´ í‰ê· \n",
    "\n",
    "# power_roll_std_7d : ë³€ë™ì„±\n",
    "\n",
    "# â¡ï¸ ëª¨ë¸ ì…ì¥ì—ì„œëŠ”:\n",
    "\n",
    "# â€œì˜¤ëŠ˜ ì „ë ¥ = ì–´ì œ ì „ë ¥ Â± ë‚ ì”¨ ì˜í–¥ Â± ìµœê·¼ ì¶”ì„¸â€\n",
    "\n",
    "# ì´ê²Œ ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ì˜ ì •ì„ ê³µì‹ì…ë‹ˆë‹¤.\n",
    "\n",
    "# 4. train_rows / test_rows ì°¨ì´ì— ëŒ€í•œ í•´ì„ (ì¤‘ìš”)\n",
    "# êµ¬ë¶„\ttrain_rows\ttest_rows\n",
    "# Baseline\t167,894\t13,514\n",
    "# FE\t120,750\t6,990\n",
    "\n",
    "# ì´ ì°¨ì´ëŠ” ë¬¸ì œê°€ ì•„ë‹ˆë¼ ì •ìƒì…ë‹ˆë‹¤.\n",
    "\n",
    "# ì´ìœ \n",
    "\n",
    "# Lag / Rolling ìƒì„± ì‹œ:\n",
    "\n",
    "# ê° ì§€ì—­ë³„ë¡œ ì´ˆê¸° 7ì¼ + ëˆ„ë½ì¼ ì œê±°\n",
    "\n",
    "# ë‚ ì§œ íŒ¨ë„ ë³´ì • ê³¼ì •ì—ì„œ ê²°ì¸¡ ì œê±°\n",
    "\n",
    "# â¡ï¸ â€œë°ì´í„°ë¥¼ í¬ìƒí•´ì„œ ì •ë³´ ë°€ë„ë¥¼ ë†’ì¸â€ ì „í˜•ì ì¸ ì‹œê³„ì—´ ì²˜ë¦¬\n",
    "\n",
    "# ì˜¤íˆë ¤:\n",
    "\n",
    "# ì ì€ ë°ì´í„°ë¡œ í›¨ì”¬ ì¢‹ì€ ì„±ëŠ¥\n",
    "# â†’ ëª¨ë¸ ì‹ ë¢°ë„ ìƒìŠ¹\n",
    "\n",
    "# 5. ì´ ê²°ê³¼ë¥¼ ë³´ê³ ì„œì— ì“°ëŠ” â€œì •ì„ ë¬¸ì¥â€\n",
    "\n",
    "# ì•„ë˜ ë¬¸ì¥ì€ ê·¸ëŒ€ë¡œ ì¨ë„ ë©ë‹ˆë‹¤.\n",
    "\n",
    "# ë‚ ì”¨ ë³€ìˆ˜ë§Œì„ ì‚¬ìš©í•œ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì€ ì „ë ¥ ì‚¬ìš©ëŸ‰ì˜ ì‹œê³„ì—´ì  íŠ¹ì„±ì„ ë°˜ì˜í•˜ì§€ ëª»í•´ ë†’ì€ ì˜ˆì¸¡ ì˜¤ì°¨ë¥¼ ë³´ì˜€ë‹¤.\n",
    "# ë°˜ë©´, ì§€ì—­ë³„ ì¼ë³„ ì „ë ¥ ì‚¬ìš©ëŸ‰ì— ëŒ€í•´ Lag ë° Rolling Featureë¥¼ ì¶”ê°€í•œ ëª¨ë¸ì€ ê³¼ê±° ì‚¬ìš© íŒ¨í„´ì„ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•¨ìœ¼ë¡œì¨ MAEì™€ RMSEë¥¼ ê°ê° ì•½ 79%, 70% ì´ìƒ ê°œì„ í•˜ì˜€ë‹¤.\n",
    "# ì´ëŠ” ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ë¬¸ì œì—ì„œ ê³¼ê±° ì‚¬ìš©ëŸ‰ ê¸°ë°˜ íŠ¹ì§•ì´ í•µì‹¬ì ì¸ ì„¤ëª…ë ¥ì„ ê°€ì§„ë‹¤ëŠ” ì ì„ ì •ëŸ‰ì ìœ¼ë¡œ ì…ì¦í•œ ê²°ê³¼ì´ë‹¤.\n",
    "\n",
    "# 6. ì§€ê¸ˆ ë‹¨ê³„ì—ì„œ â€œì´ë¯¸ í™•ë³´í•œ ê²ƒâ€\n",
    "\n",
    "# ì´ í”„ë¡œì íŠ¸ ê¸°ì¤€ìœ¼ë¡œ, ë‹¹ì‹ ì€ ì´ë¯¸ ë‹¤ìŒì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "# âœ… ê³µì •í•œ Baseline vs FE ë¹„êµ ì‹¤í—˜\n",
    "\n",
    "# âœ… ì‹œê³„ì—´ ìê¸°ìƒê´€ì˜ ì¤‘ìš”ì„±ì— ëŒ€í•œ ì •ëŸ‰ ì¦ê±°\n",
    "\n",
    "# âœ… ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ êµ¬ì¡°(ë‚ ì§œ ê¸°ì¤€ split)\n",
    "\n",
    "# âœ… ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì“°ëŠ” Feature êµ¬ì„±\n",
    "\n",
    "# ğŸ‘‰ ì´ ìƒíƒœë§Œìœ¼ë¡œë„ â€œEDA + Feature Engineering + ML ëª¨ë¸ë§â€ íŒŒíŠ¸ëŠ” ì™„ì„±ì…ë‹ˆë‹¤.\n",
    "\n",
    "# 7. ë‹¤ìŒ ë‹¨ê³„ ì¶”ì²œ (ìš°ì„ ìˆœìœ„)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp(ipykernel)",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
