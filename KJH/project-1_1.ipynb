{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9521dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶”ê°€ ìˆ˜ì •\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e96b0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ë²•ì •ë™ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: (1112, 3)\n"
     ]
    }
   ],
   "source": [
    "# 1ë‹¨ê³„: ë²•ì •ë™ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "# 1-1 ë²•ì •ë™ ë°ì´í„° ë¡œë“œí•˜ê¸°\n",
    "file_path = \"data/ë²•ì •ë™ì½”ë“œ ì¡°íšŒìë£Œ.xls\"\n",
    "dong_df = pd.read_excel(file_path)\n",
    "print(f\"âœ“ ë²•ì •ë™ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {dong_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a19576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-2 ì „ì²´ì½”ë“œ ë¶„ë¦¬ (ì• 5ìë¦¬/ë’¤ 5ìë¦¬)\n",
    "dong_df[\"ë²•ì •ë™ì½”ë“œ\"] = dong_df[\"ë²•ì •ë™ì½”ë“œ\"].astype(str).str.zfill(10)\n",
    "dong_df[\"ì‹œêµ°êµ¬ì½”ë“œ\"] = dong_df[\"ë²•ì •ë™ì½”ë“œ\"].str[:5]\n",
    "dong_df[\"ë²•ì •ë™ì½”ë“œ_í•˜ìœ„\"] = dong_df[\"ë²•ì •ë™ì½”ë“œ\"].str[5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9359dab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ìƒìœ„ í–‰ì •êµ¬ì—­ ì œê±°: 1112 â†’ 1086\n"
     ]
    }
   ],
   "source": [
    "# 1-3 ìƒìœ„ í–‰ì •êµ¬ì—­ ì œê±°\n",
    "before = len(dong_df)\n",
    "dong_df = dong_df[dong_df[\"ë²•ì •ë™ì½”ë“œ_í•˜ìœ„\"] != \"00000\"].copy()\n",
    "print(f\"âœ“ ìƒìœ„ í–‰ì •êµ¬ì—­ ì œê±°: {before} â†’ {len(dong_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd177d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ë²•ì •ë™ ë§ˆìŠ¤í„° ìƒì„±: (1086, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1-4 ë²•ì •ë™ ì „ì²´ëª… ë¶„ë¦¬\n",
    "dong_df[\"ë²•ì •ë™ëª…\"] = dong_df[\"ë²•ì •ë™ëª…\"].astype(str).str.strip()\n",
    "dong_df[\"ì‹œêµ°êµ¬ëª…\"] = dong_df[\"ë²•ì •ë™ëª…\"].apply(lambda x: \" \".join(x.split()[:-1]))\n",
    "dong_df[\"ë²•ì •ë™ëª…_í•˜ìœ„\"] = dong_df[\"ë²•ì •ë™ëª…\"].apply(lambda x: x.split()[-1])\n",
    "\n",
    "dong_clean = dong_df[[\n",
    "    \"ë²•ì •ë™ì½”ë“œ\", \"ì‹œêµ°êµ¬ì½”ë“œ\", \"ë²•ì •ë™ì½”ë“œ_í•˜ìœ„\", \n",
    "    \"ì‹œêµ°êµ¬ëª…\", \"ë²•ì •ë™ëª…_í•˜ìœ„\"\n",
    "]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "dong_clean.to_csv(\"data/ë²•ì •ë™_ë§ˆìŠ¤í„°.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"âœ“ ë²•ì •ë™ ë§ˆìŠ¤í„° ìƒì„±: {dong_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bb11fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ì „ë ¥ëŸ‰ ë°ì´í„° ë¡œë“œ: (9754804, 5)\n"
     ]
    }
   ],
   "source": [
    "# 2ë‹¨ê³„: ì „ë ¥ëŸ‰ ë°ì´í„° ì „ì²˜ë¦¬ (ê³ ë„í™”)\n",
    "# 2-1 ì „ë ¥ëŸ‰ ë°ì´í„°(ë²•ì •ë™ë³„ì‹œê°„ë³„ì „ë ¥ì‚¬ìš©ëŸ‰.csv) ë¡œë“œí•˜ê¸°\n",
    "power_path = \"data/ë²•ì •ë™ë³„ì‹œê°„ë³„ì „ë ¥ì‚¬ìš©ëŸ‰.csv\"\n",
    "try:\n",
    "    power_df = pd.read_csv(power_path, encoding=\"utf-8-sig\")\n",
    "except UnicodeDecodeError:\n",
    "    power_df = pd.read_csv(power_path, encoding=\"cp949\")\n",
    "print(f\"âœ“ ì „ë ¥ëŸ‰ ë°ì´í„° ë¡œë“œ: {power_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59b79e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ì¤‘ë³µ ì œê±°: 9754804 â†’ 4348560\n"
     ]
    }
   ],
   "source": [
    "# 2-2 ì¤‘ë³µ ì œê±°\n",
    "before = len(power_df)\n",
    "power_df = power_df.drop_duplicates().copy()\n",
    "print(f\"âœ“ ì¤‘ë³µ ì œê±°: {before} â†’ {len(power_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeac85dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë²•ì •ë™ì½”ë“œ ìƒì„±\n",
    "power_df[\"SIGUNGU_CD\"] = power_df[\"SIGUNGU_CD\"].astype(str).str.zfill(5)\n",
    "power_df[\"BJDONG_CD\"] = power_df[\"BJDONG_CD\"].astype(str).str.zfill(5)\n",
    "power_df[\"ë²•ì •ë™ì½”ë“œ\"] = power_df[\"SIGUNGU_CD\"] + power_df[\"BJDONG_CD\"]\n",
    "\n",
    "# ì¼ì‹œ ìƒì„±\n",
    "power_df[\"USE_YM\"] = power_df[\"USE_YM\"].astype(str)\n",
    "power_df[\"USE_HM\"] = power_df[\"USE_HM\"].astype(str).str.zfill(4)\n",
    "power_df[\"ì¼ì‹œ\"] = pd.to_datetime(\n",
    "    power_df[\"USE_YM\"].str[:8] + power_df[\"USE_HM\"],\n",
    "    format=\"%Y%m%d%H%M\", \n",
    "    errors=\"coerce\"\n",
    ")\n",
    "power_df[\"ì¼ì\"] = power_df[\"ì¼ì‹œ\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36ea579c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì‹œê°„ ì •í•©ì„± ê²€ì¦]\n",
      "âœ“ ì¤‘ë³µ ì‹œê°„ ì—†ìŒ\n",
      "âœ“ ì‹œê°„ë³„ ë°ì´í„° ìƒì„±: (4348560, 11)\n"
     ]
    }
   ],
   "source": [
    "# 2-3 ì „ë ¥ë°ì´í„°ë¥¼ ì‹œê°„ë‹¹ -> ì¼ë‹¹ ë³€ê²½í•´ë³´ê¸°\n",
    "# ì „ë ¥ëŸ‰ ìˆ«ì ë³€í™˜\n",
    "power_df[\"FDRCT_VLD_KWH\"] = pd.to_numeric(power_df[\"FDRCT_VLD_KWH\"], errors=\"coerce\")\n",
    "\n",
    "# ğŸ”¥ NEW: ì‹œê°„ ëˆ„ë½/ì¤‘ë³µ ê²€ì¦\n",
    "print(\"\\n[ì‹œê°„ ì •í•©ì„± ê²€ì¦]\")\n",
    "time_check = power_df.groupby([\"ë²•ì •ë™ì½”ë“œ\", \"ì¼ì‹œ\"]).size().reset_index(name='count')\n",
    "duplicates = time_check[time_check['count'] > 1]\n",
    "if len(duplicates) > 0:\n",
    "    print(f\"âš ï¸ ì¤‘ë³µ ì‹œê°„ ë°œê²¬: {len(duplicates)}ê±´ â†’ í‰ê· ê°’ìœ¼ë¡œ ì§‘ê³„\")\n",
    "    power_df = power_df.groupby([\"ë²•ì •ë™ì½”ë“œ\", \"ì¼ì‹œ\"], as_index=False)[\"FDRCT_VLD_KWH\"].mean()\n",
    "else:\n",
    "    print(\"âœ“ ì¤‘ë³µ ì‹œê°„ ì—†ìŒ\")\n",
    "\n",
    "# ğŸ”¥ NEW: ì‹œê°„ë³„ ë°ì´í„°ë¡œ ë³€í™˜ (ì¼ë³„ ëŒ€ì‹ )\n",
    "power_hourly = power_df.copy()\n",
    "power_hourly[\"ì¼ì\"] = power_hourly[\"ì¼ì‹œ\"].dt.date\n",
    "power_hourly[\"ì‹œê°„\"] = power_hourly[\"ì¼ì‹œ\"].dt.hour\n",
    "power_hourly[\"ë…„\"] = power_hourly[\"ì¼ì‹œ\"].dt.year  \n",
    "power_hourly[\"ì›”\"] = power_hourly[\"ì¼ì‹œ\"].dt.month\n",
    "\n",
    "print(f\"âœ“ ì‹œê°„ë³„ ë°ì´í„° ìƒì„±: {power_hourly.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9255df99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì „ë ¥ëŸ‰ ì´ìƒì¹˜ ì™„í™”]\n",
      "âœ“ Winsorizing ì™„ë£Œ (0.5~99.5% ê¸°ì¤€)\n",
      "âœ“ ì €ì „ë ¥ í”Œë˜ê·¸ ìƒì„± (í•˜ìœ„ 2% ê¸°ì¤€)\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¥ NEW: ì´ìƒì¹˜ ì™„í™” (ì œê±° X, Winsorizing)\n",
    "print(\"\\n[ì „ë ¥ëŸ‰ ì´ìƒì¹˜ ì™„í™”]\")\n",
    "def winsorize_power(group):\n",
    "    upper = group[\"FDRCT_VLD_KWH\"].quantile(0.995)\n",
    "    lower = group[\"FDRCT_VLD_KWH\"].quantile(0.005)\n",
    "    group[\"ì „ë ¥ëŸ‰_ì›ë³¸\"] = group[\"FDRCT_VLD_KWH\"]\n",
    "    group[\"ì „ë ¥ëŸ‰_ì™„í™”\"] = group[\"FDRCT_VLD_KWH\"].clip(lower, upper)\n",
    "    return group\n",
    "\n",
    "power_hourly = power_hourly.groupby(\"ë²•ì •ë™ì½”ë“œ\", group_keys=False).apply(winsorize_power)\n",
    "print(f\"âœ“ Winsorizing ì™„ë£Œ (0.5~99.5% ê¸°ì¤€)\")\n",
    "\n",
    "# ğŸ”¥ NEW: ì €ì „ë ¥ í”Œë˜ê·¸ ë³€ìˆ˜\n",
    "power_hourly[\"ì €ì „ë ¥_í”Œë˜ê·¸\"] = 0\n",
    "for dong in power_hourly[\"ë²•ì •ë™ì½”ë“œ\"].unique():\n",
    "    mask = power_hourly[\"ë²•ì •ë™ì½”ë“œ\"] == dong\n",
    "    threshold = power_hourly.loc[mask, \"ì „ë ¥ëŸ‰_ì™„í™”\"].quantile(0.02)\n",
    "    power_hourly.loc[mask & (power_hourly[\"ì „ë ¥ëŸ‰_ì™„í™”\"] < threshold), \"ì €ì „ë ¥_í”Œë˜ê·¸\"] = 1\n",
    "\n",
    "print(f\"âœ“ ì €ì „ë ¥ í”Œë˜ê·¸ ìƒì„± (í•˜ìœ„ 2% ê¸°ì¤€)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6be7522c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ë²•ì •ë™ ë§ˆìŠ¤í„°ì™€ ë³‘í•©: (4348560, 16)\n",
      "âœ“ ì €ì¥: data/ì „ë ¥_ì‹œê°„ë³„_ë³‘í•©.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2-4. ë²•ì •ë™ ë³‘í•©\n",
    "merged_power = power_hourly.merge(dong_clean, on=\"ë²•ì •ë™ì½”ë“œ\", how=\"left\")\n",
    "print(f\"âœ“ ë²•ì •ë™ ë§ˆìŠ¤í„°ì™€ ë³‘í•©: {merged_power.shape}\")\n",
    "\n",
    "merged_power.to_csv(\"data/ì „ë ¥_ì‹œê°„ë³„_ë³‘í•©.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"âœ“ ì €ì¥: data/ì „ë ¥_ì‹œê°„ë³„_ë³‘í•©.csv\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bce6fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ì‹œê°„ë³„ ë‚ ì”¨ ë°ì´í„° ë¡œë“œ: (26304, 27)\n"
     ]
    }
   ],
   "source": [
    "# 3ë‹¨ê³„: ë‚ ì”¨ ë°ì´í„° ì „ì²˜ë¦¬ (ê³ ë„í™”)\n",
    " # 1-1 ë‚ ì”¨ë°ì´í„°ì˜ ë¹ˆì¸¡ì¹˜ë‚˜ ê²°ì¸¡ì¹˜ ì•Œì•„ë³´ê¸°\n",
    "base_dir = \"data/weather_data\"\n",
    "\n",
    "# ì‹œê°„ë³„(HR) ë°ì´í„° ë¡œë“œ (ì¼ë³„ ëŒ€ì‹  ì‹œê°„ë³„ ì‚¬ìš©)\n",
    "hr_files = [\n",
    "    \"SURFACE_ASOS_108_HR_2022_2022_2023.csv\",\n",
    "    \"SURFACE_ASOS_108_HR_2023_2023_2024.csv\",\n",
    "    \"SURFACE_ASOS_108_HR_2024_2024_2025.csv\"\n",
    "]\n",
    "\n",
    "hr_dfs = []\n",
    "for f in hr_files:\n",
    "    fpath = os.path.join(base_dir, f)\n",
    "    try:\n",
    "        df = pd.read_csv(fpath, encoding=\"utf-8-sig\")\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(fpath, encoding=\"cp949\")\n",
    "    hr_dfs.append(df)\n",
    "\n",
    "weather_hr = pd.concat(hr_dfs, ignore_index=True)\n",
    "print(f\"âœ“ ì‹œê°„ë³„ ë‚ ì”¨ ë°ì´í„° ë¡œë“œ: {weather_hr.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "313b7b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ë‚ ì§œ/ì‹œê°„ ë³€í™˜ ì™„ë£Œ: ì¼ì‹œ â†’ ì¼ì‹œ\n",
      "âœ“ ë‚ ì”¨ ì»¬ëŸ¼ ì„ íƒ: ['ì¼ì‹œ', 'ì¼ì', 'ì‹œê°„', 'ê¸°ì˜¨', 'ê°•ìˆ˜ëŸ‰', 'í’ì†', 'ìŠµë„']\n"
     ]
    }
   ],
   "source": [
    "# ë‚ ì§œ/ì‹œê°„ ì»¬ëŸ¼ íƒì§€\n",
    "date_col = None\n",
    "for c in weather_hr.columns:\n",
    "    if any(k in str(c).lower() for k in [\"tm\", \"ì¼ì‹œ\", \"time\"]):\n",
    "        s = pd.to_datetime(weather_hr[c], errors=\"coerce\")\n",
    "        if s.notna().sum() > len(weather_hr) * 0.9:\n",
    "            date_col = c\n",
    "            weather_hr[\"ì¼ì‹œ\"] = s\n",
    "            break\n",
    "\n",
    "if date_col is None:\n",
    "    raise ValueError(\"ë‚ ì”¨ ë°ì´í„°ì—ì„œ ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "weather_hr[\"ì¼ì\"] = weather_hr[\"ì¼ì‹œ\"].dt.date\n",
    "weather_hr[\"ì‹œê°„\"] = weather_hr[\"ì¼ì‹œ\"].dt.hour\n",
    "print(f\"âœ“ ë‚ ì§œ/ì‹œê°„ ë³€í™˜ ì™„ë£Œ: {date_col} â†’ ì¼ì‹œ\")\n",
    "\n",
    "# í•„ìš”í•œ ì»¬ëŸ¼ ë§¤í•‘ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ëª… ì‚¬ìš©)\n",
    "col_mapping = {\n",
    "    \"ê¸°ì˜¨(Â°C)\": \"ê¸°ì˜¨\",\n",
    "    \"ê°•ìˆ˜ëŸ‰(mm)\": \"ê°•ìˆ˜ëŸ‰\", \n",
    "    \"í’ì†(m/s)\": \"í’ì†\",\n",
    "    \"ìŠµë„(%)\": \"ìŠµë„\"\n",
    "}\n",
    "\n",
    "use_cols = [\"ì¼ì‹œ\", \"ì¼ì\", \"ì‹œê°„\"]\n",
    "for orig, new in col_mapping.items():\n",
    "    if orig in weather_hr.columns:\n",
    "        weather_hr[new] = pd.to_numeric(weather_hr[orig], errors=\"coerce\")\n",
    "        use_cols.append(new)\n",
    "\n",
    "weather_clean = weather_hr[use_cols].copy()\n",
    "print(f\"âœ“ ë‚ ì”¨ ì»¬ëŸ¼ ì„ íƒ: {weather_clean.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbc7189e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ê²°ì¸¡ì¹˜ ì²˜ë¦¬]\n",
      "âœ“ ê°•ìˆ˜ëŸ‰ ê²°ì¸¡ì¹˜ â†’ 0\n",
      "âœ“ ê¸°ì˜¨ ê²°ì¸¡ì¹˜ ë³´ê°„: 0 â†’ 0\n",
      "âœ“ í’ì† ê²°ì¸¡ì¹˜ ë³´ê°„: 68 â†’ 0\n",
      "âœ“ ìŠµë„ ê²°ì¸¡ì¹˜ ë³´ê°„: 0 â†’ 0\n",
      "\n",
      "[ê¸°ìƒ íŒŒìƒ ë³€ìˆ˜ ìƒì„±]\n",
      "âœ“ ë¶ˆì¾Œì§€ìˆ˜ ìƒì„±\n",
      "âœ“ ëƒ‰ë‚œë°©ë„ì¼ ìƒì„±\n",
      "âœ“ ê¸°ì˜¨ ë³€í™”ëŸ‰ ìƒì„± (1h, 24h)\n",
      "âœ“ ê°•ìˆ˜ ì—¬ë¶€ í”Œë˜ê·¸ ìƒì„±\n",
      "âœ“ ì €ì¥: data/ë‚ ì”¨_ì‹œê°„ë³„_ì •ì œ.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¥ NEW: ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ê°•ìˆ˜ëŸ‰=0, ë‚˜ë¨¸ì§€=ë³´ê°„)\n",
    "print(\"\\n[ê²°ì¸¡ì¹˜ ì²˜ë¦¬]\")\n",
    "if \"ê°•ìˆ˜ëŸ‰\" in weather_clean.columns:\n",
    "    weather_clean[\"ê°•ìˆ˜ëŸ‰\"] = weather_clean[\"ê°•ìˆ˜ëŸ‰\"].fillna(0)\n",
    "    print(\"âœ“ ê°•ìˆ˜ëŸ‰ ê²°ì¸¡ì¹˜ â†’ 0\")\n",
    "\n",
    "for col in [\"ê¸°ì˜¨\", \"í’ì†\", \"ìŠµë„\"]:\n",
    "    if col in weather_clean.columns:\n",
    "        before_na = weather_clean[col].isna().sum()\n",
    "        weather_clean[col] = weather_clean[col].interpolate(method=\"linear\")\n",
    "        weather_clean[col] = weather_clean[col].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "        print(f\"âœ“ {col} ê²°ì¸¡ì¹˜ ë³´ê°„: {before_na} â†’ {weather_clean[col].isna().sum()}\")\n",
    "\n",
    "# ğŸ”¥ NEW: ì²´ê° ê´€ë ¨ íŒŒìƒ ë³€ìˆ˜\n",
    "print(\"\\n[ê¸°ìƒ íŒŒìƒ ë³€ìˆ˜ ìƒì„±]\")\n",
    "\n",
    "if \"ê¸°ì˜¨\" in weather_clean.columns and \"ìŠµë„\" in weather_clean.columns:\n",
    "    # ë¶ˆì¾Œì§€ìˆ˜\n",
    "    T = weather_clean[\"ê¸°ì˜¨\"]\n",
    "    RH = weather_clean[\"ìŠµë„\"]\n",
    "    weather_clean[\"ë¶ˆì¾Œì§€ìˆ˜\"] = 0.81 * T + 0.01 * RH * (0.99 * T - 14.3) + 46.3\n",
    "    print(\"âœ“ ë¶ˆì¾Œì§€ìˆ˜ ìƒì„±\")\n",
    "    \n",
    "    # ëƒ‰ë‚œë°©ë„ì¼\n",
    "    weather_clean[\"ëƒ‰ë°©ë„ì¼\"] = (weather_clean[\"ê¸°ì˜¨\"] - 24).clip(lower=0)\n",
    "    weather_clean[\"ë‚œë°©ë„ì¼\"] = (18 - weather_clean[\"ê¸°ì˜¨\"]).clip(lower=0)\n",
    "    print(\"âœ“ ëƒ‰ë‚œë°©ë„ì¼ ìƒì„±\")\n",
    "\n",
    "# ğŸ”¥ NEW: ê¸°ì˜¨ ë³€í™”ëŸ‰\n",
    "if \"ê¸°ì˜¨\" in weather_clean.columns:\n",
    "    weather_clean = weather_clean.sort_values([\"ì¼ì‹œ\"]).reset_index(drop=True)\n",
    "    weather_clean[\"ê¸°ì˜¨ë³€í™”_1h\"] = weather_clean[\"ê¸°ì˜¨\"].diff(1)\n",
    "    weather_clean[\"ê¸°ì˜¨ë³€í™”_24h\"] = weather_clean[\"ê¸°ì˜¨\"].diff(24)\n",
    "    weather_clean[\"ê¸°ì˜¨ë³€í™”_1h\"] = weather_clean[\"ê¸°ì˜¨ë³€í™”_1h\"].fillna(0)\n",
    "    weather_clean[\"ê¸°ì˜¨ë³€í™”_24h\"] = weather_clean[\"ê¸°ì˜¨ë³€í™”_24h\"].fillna(0)\n",
    "    print(\"âœ“ ê¸°ì˜¨ ë³€í™”ëŸ‰ ìƒì„± (1h, 24h)\")\n",
    "\n",
    "# ğŸ”¥ NEW: ê°•ìˆ˜ ì—¬ë¶€ í”Œë˜ê·¸\n",
    "if \"ê°•ìˆ˜ëŸ‰\" in weather_clean.columns:\n",
    "    weather_clean[\"ê°•ìˆ˜ì—¬ë¶€\"] = (weather_clean[\"ê°•ìˆ˜ëŸ‰\"] > 0).astype(int)\n",
    "    print(\"âœ“ ê°•ìˆ˜ ì—¬ë¶€ í”Œë˜ê·¸ ìƒì„±\")\n",
    "\n",
    "# ì‹œêµ°êµ¬ì½”ë“œ ë¶€ì—¬ (ì„œìš¸: 11000)\n",
    "weather_clean[\"ì‹œêµ°êµ¬ì½”ë“œ\"] = \"11000\"\n",
    "\n",
    "weather_clean.to_csv(\"data/ë‚ ì”¨_ì‹œê°„ë³„_ì •ì œ.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"âœ“ ì €ì¥: data/ë‚ ì”¨_ì‹œê°„ë³„_ì •ì œ.csv\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cacd64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ì „ë ¥+ë‚ ì”¨ ë³‘í•© ì™„ë£Œ: (4348560, 27)\n",
      "\n",
      "[ì‹œê°„ íŒŒìƒ ë³€ìˆ˜ ìƒì„±]\n",
      "âœ“ ì‹œê°„ íŒŒìƒ ë³€ìˆ˜ ìƒì„± (ë…„ì›”ì¼, ìš”ì¼, ì£¼ë§, ê³µíœ´ì¼)\n",
      "\n",
      "[ë²•ì •ë™ë³„ í†µê³„ Feature ìƒì„± (Train ê¸°ê°„ ê¸°ì¤€)]\n",
      "âœ“ ë²•ì •ë™ í†µê³„ Feature ë³‘í•© ì™„ë£Œ\n",
      "\n",
      "âœ… ìµœì¢… ë°ì´í„° ì €ì¥ ì™„ë£Œ: data/ìµœì¢…_í†µí•©ë°ì´í„°_ì‹œê°„ë³„.csv\n",
      "   - ì´ ë°ì´í„° ìˆ˜: 4,348,560ê°œ\n",
      "   - ì»¬ëŸ¼ ìˆ˜: 37ê°œ\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'datetime.date' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 76\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - ì´ ë°ì´í„° ìˆ˜: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(final_df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mê°œ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - ì»¬ëŸ¼ ìˆ˜: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(final_df\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mê°œ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - ê¸°ê°„: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mfinal_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mì¼ì\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ~ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mì¼ì\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - ë²•ì •ë™ ìˆ˜: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124më²•ì •ë™ì½”ë“œ\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mê°œ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# ë°ì´í„° í’ˆì§ˆ ì²´í¬\u001b[39;00m\n",
      "File \u001b[1;32mc:\\project-AI\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:11965\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.min\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11945\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11946\u001b[0m     _num_doc,\n\u001b[0;32m  11947\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the minimum of the values over the requested axis.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11963\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11964\u001b[0m ):\n\u001b[1;32m> 11965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m, axis, skipna, level, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\project-AI\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:11365\u001b[0m, in \u001b[0;36mNDFrame.min\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmin\u001b[39m(\n\u001b[0;32m  11358\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11359\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11363\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11364\u001b[0m ):\n\u001b[1;32m> 11365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11366\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m  11367\u001b[0m         nanops\u001b[38;5;241m.\u001b[39mnanmin,\n\u001b[0;32m  11368\u001b[0m         axis,\n\u001b[0;32m  11369\u001b[0m         skipna,\n\u001b[0;32m  11370\u001b[0m         level,\n\u001b[0;32m  11371\u001b[0m         numeric_only,\n\u001b[0;32m  11372\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11373\u001b[0m     )\n",
      "File \u001b[1;32mc:\\project-AI\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m  11349\u001b[0m     )\n\u001b[0;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[0;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  11352\u001b[0m     )\n\u001b[1;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  11355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\project-AI\\.venv\\lib\\site-packages\\pandas\\core\\series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4814\u001b[0m     )\n\u001b[0;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\project-AI\\.venv\\lib\\site-packages\\pandas\\core\\nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\project-AI\\.venv\\lib\\site-packages\\pandas\\core\\nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32mc:\\project-AI\\.venv\\lib\\site-packages\\pandas\\core\\nanops.py:1051\u001b[0m, in \u001b[0;36m_nanminmax.<locals>.reduction\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1051\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1053\u001b[0m result \u001b[38;5;241m=\u001b[39m _maybe_null_out(result, axis, mask, values\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\project-AI\\.venv\\lib\\site-packages\\numpy\\core\\_methods.py:44\u001b[0m, in \u001b[0;36m_amin\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     43\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_minimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'datetime.date' and 'float'"
     ]
    }
   ],
   "source": [
    "# 3-4 ë‹¤ë¥¸ ë°ì´í„°ë“¤ê³¼ í•©ì¹˜ê¸°\n",
    "# ì¼ì‹œ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•© (ì •í™•í•œ ì‹œê°„ ë§¤ì¹­)\n",
    "final_df = merged_power.merge(\n",
    "    weather_clean,\n",
    "    on=[\"ì¼ì\", \"ì‹œê°„\", \"ì‹œêµ°êµ¬ì½”ë“œ\"],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_ë‚ ì”¨\")\n",
    ")\n",
    "\n",
    "print(f\"âœ“ ì „ë ¥+ë‚ ì”¨ ë³‘í•© ì™„ë£Œ: {final_df.shape}\")\n",
    "\n",
    "# ğŸ”¥ NEW: ì‹œê°„ íŒŒìƒ ë³€ìˆ˜\n",
    "print(\"\\n[ì‹œê°„ íŒŒìƒ ë³€ìˆ˜ ìƒì„±]\")\n",
    "final_df[\"ì¼ì‹œ\"] = pd.to_datetime(final_df[\"ì¼ì‹œ\"])\n",
    "final_df[\"ë…„\"] = final_df[\"ì¼ì‹œ\"].dt.year\n",
    "final_df[\"ì›”\"] = final_df[\"ì¼ì‹œ\"].dt.month\n",
    "final_df[\"ì¼\"] = final_df[\"ì¼ì‹œ\"].dt.day\n",
    "final_df[\"ìš”ì¼\"] = final_df[\"ì¼ì‹œ\"].dt.dayofweek  # 0=ì›”ìš”ì¼\n",
    "final_df[\"ì£¼ë§ì—¬ë¶€\"] = (final_df[\"ìš”ì¼\"] >= 5).astype(int)\n",
    "\n",
    "# ğŸ”¥ NEW: ê³µíœ´ì¼ í”Œë˜ê·¸ (ê°„ë‹¨ ë²„ì „ - ì‹¤ì œë¡  ê³µê³µë°ì´í„° API ì‚¬ìš© ê¶Œì¥)\n",
    "holidays_2022_2025 = [\n",
    "    # 2022ë…„\n",
    "    \"2022-01-01\", \"2022-01-31\", \"2022-02-01\", \"2022-02-02\", \"2022-03-01\",\n",
    "    \"2022-03-09\", \"2022-05-05\", \"2022-05-08\", \"2022-06-06\", \"2022-08-15\",\n",
    "    \"2022-09-09\", \"2022-09-10\", \"2022-09-11\", \"2022-10-03\", \"2022-10-09\",\n",
    "    \"2022-10-10\", \"2022-12-25\",\n",
    "    # 2023ë…„\n",
    "    \"2023-01-01\", \"2023-01-21\", \"2023-01-22\", \"2023-01-23\", \"2023-01-24\",\n",
    "    \"2023-03-01\", \"2023-05-05\", \"2023-05-27\", \"2023-06-06\", \"2023-08-15\",\n",
    "    \"2023-09-28\", \"2023-09-29\", \"2023-09-30\", \"2023-10-03\", \"2023-10-09\",\n",
    "    \"2023-12-25\",\n",
    "    # 2024ë…„\n",
    "    \"2024-01-01\", \"2024-02-09\", \"2024-02-10\", \"2024-02-11\", \"2024-02-12\",\n",
    "    \"2024-03-01\", \"2024-04-10\", \"2024-05-05\", \"2024-05-06\", \"2024-05-15\",\n",
    "    \"2024-06-06\", \"2024-08-15\", \"2024-09-16\", \"2024-09-17\", \"2024-09-18\",\n",
    "    \"2024-10-03\", \"2024-10-09\", \"2024-12-25\",\n",
    "    # 2025ë…„\n",
    "    \"2025-01-01\", \"2025-01-28\", \"2025-01-29\", \"2025-01-30\", \"2025-03-01\",\n",
    "    \"2025-03-03\", \"2025-05-05\", \"2025-05-06\", \"2025-06-06\", \"2025-08-15\",\n",
    "    \"2025-10-03\", \"2025-10-05\", \"2025-10-06\", \"2025-10-07\", \"2025-10-08\",\n",
    "    \"2025-10-09\", \"2025-12-25\"\n",
    "]\n",
    "holidays = pd.to_datetime(holidays_2022_2025).date\n",
    "final_df[\"ê³µíœ´ì¼ì—¬ë¶€\"] = final_df[\"ì¼ì\"].isin(holidays).astype(int)\n",
    "\n",
    "print(\"âœ“ ì‹œê°„ íŒŒìƒ ë³€ìˆ˜ ìƒì„± (ë…„ì›”ì¼, ìš”ì¼, ì£¼ë§, ê³µíœ´ì¼)\")\n",
    "\n",
    "# ğŸ”¥ NEW: ë²•ì •ë™ë³„ í†µê³„ Feature (Train ê¸°ê°„ ê¸°ì¤€)\n",
    "print(\"\\n[ë²•ì •ë™ë³„ í†µê³„ Feature ìƒì„± (Train ê¸°ê°„ ê¸°ì¤€)]\")\n",
    "\n",
    "# Train ê¸°ê°„: 2022~2024ë…„\n",
    "train_mask = final_df[\"ë…„\"] <= 2024\n",
    "train_data = final_df[train_mask].copy()\n",
    "\n",
    "dong_stats = train_data.groupby(\"ë²•ì •ë™ì½”ë“œ\").agg({\n",
    "    \"ì „ë ¥ëŸ‰_ì™„í™”\": [\"mean\", \"std\", \"max\"]\n",
    "}).reset_index()\n",
    "dong_stats.columns = [\"ë²•ì •ë™ì½”ë“œ\", \"ë²•ì •ë™_í‰ê· ì „ë ¥\", \"ë²•ì •ë™_í‘œì¤€í¸ì°¨\", \"ë²•ì •ë™_ìµœëŒ€ì „ë ¥\"]\n",
    "\n",
    "# ì‹œê°„ëŒ€ë³„ í‰ê· \n",
    "dong_hour_stats = train_data.groupby([\"ë²•ì •ë™ì½”ë“œ\", \"ì‹œê°„\"])[\"ì „ë ¥ëŸ‰_ì™„í™”\"].mean().reset_index()\n",
    "dong_hour_stats.columns = [\"ë²•ì •ë™ì½”ë“œ\", \"ì‹œê°„\", \"ë²•ì •ë™_ì‹œê°„í‰ê· ì „ë ¥\"]\n",
    "\n",
    "# ë³‘í•©\n",
    "final_df = final_df.merge(dong_stats, on=\"ë²•ì •ë™ì½”ë“œ\", how=\"left\")\n",
    "final_df = final_df.merge(dong_hour_stats, on=[\"ë²•ì •ë™ì½”ë“œ\", \"ì‹œê°„\"], how=\"left\")\n",
    "\n",
    "print(\"âœ“ ë²•ì •ë™ í†µê³„ Feature ë³‘í•© ì™„ë£Œ\")\n",
    "\n",
    "# ìµœì¢… ì €ì¥\n",
    "final_df.to_csv(\"data/ìµœì¢…_í†µí•©ë°ì´í„°_ì‹œê°„ë³„.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nâœ… ìµœì¢… ë°ì´í„° ì €ì¥ ì™„ë£Œ: data/ìµœì¢…_í†µí•©ë°ì´í„°_ì‹œê°„ë³„.csv\")\n",
    "print(f\"   - ì´ ë°ì´í„° ìˆ˜: {len(final_df):,}ê°œ\")\n",
    "print(f\"   - ì»¬ëŸ¼ ìˆ˜: {len(final_df.columns)}ê°œ\")\n",
    "print(f\"   - ê¸°ê°„: {final_df['ì¼ì'].min()} ~ {final_df['ì¼ì'].max()}\")\n",
    "print(f\"   - ë²•ì •ë™ ìˆ˜: {final_df['ë²•ì •ë™ì½”ë“œ'].nunique()}ê°œ\")\n",
    "\n",
    "# ë°ì´í„° í’ˆì§ˆ ì²´í¬\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ë°ì´í„° í’ˆì§ˆ ì²´í¬\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ê²°ì¸¡ì¹˜ í˜„í™©:\")\n",
    "null_summary = final_df.isnull().sum()\n",
    "print(null_summary[null_summary > 0])\n",
    "\n",
    "print(\"\\nì£¼ìš” ì»¬ëŸ¼ í†µê³„:\")\n",
    "important_cols = [\"ì „ë ¥ëŸ‰_ì™„í™”\", \"ê¸°ì˜¨\", \"ë¶ˆì¾Œì§€ìˆ˜\", \"ëƒ‰ë°©ë„ì¼\", \"ë‚œë°©ë„ì¼\"]\n",
    "for col in important_cols:\n",
    "    if col in final_df.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(final_df[col].describe())\n",
    "\n",
    "print(\"\\nâœ… ì „ì²´ ì „ì²˜ë¦¬ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d65506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92121503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ee385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
